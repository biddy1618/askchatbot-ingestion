{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy \n",
    "import os \n",
    "from tqdm import tqdm \n",
    "import requests \n",
    "import json \n",
    "import re \n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from elasticsearch.helpers import bulk\n",
    "from elasticsearch import Elasticsearch\n",
    "from torch import bfloat16\n",
    "import time\n",
    "\n",
    "\n",
    "# Initializing models\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "model = SentenceTransformer('./model').to('cuda').to(bfloat16)\n",
    "MAX_LENGTH = model.max_seq_length\n",
    "VECTOR_SIZE = model[1].word_embedding_dimension\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "# Elastic Search settings \n",
    "#SETTINGS =  {\"number_of_shards\": 2, \"number_of_replicas\": 1}\n",
    "MAPPINGS =  {\n",
    "        \"dynamic\"   : \"false\",\n",
    "        \"properties\": {\n",
    "            \"source\"        : {\"type\": \"keyword\", \"index\": \"false\" , \"ignore_above\": 32766},\n",
    "            \"url\"           : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"title\"         : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"text\"          : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"subHead\"       : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"thumbnail\"     : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"vector\"        : {\"type\": \"dense_vector\", \"dims\": VECTOR_SIZE}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Creating a folder to store the data. Will also be ingested into ES\n",
    "DATA_PATH = './cleaned_new'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "\n",
    "def get_token_length(txt: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a string\"\"\"\n",
    "    return tokenizer(txt, return_tensors='pt')['input_ids'].shape[1]\n",
    "\n",
    "def process_long_text(txt: str, chunk_length: int = 3) -> list:\n",
    "    \"\"\"Splits longer texts into chunks of 3 sentences. Returns individual sentences if this is not possible\"\"\"\n",
    "    sentences = [x for sen in nlp(txt).sents if (x:=sen.text.strip())]\n",
    "    if len(sentences) >= chunk_length:\n",
    "        return [' '.join(sentences[i:i+chunk_length])for i in range(0, len(sentences), chunk_length)]\n",
    "    else:\n",
    "        return sentences\n",
    "    \n",
    "    \n",
    "def clean_header(header: str) -> str:\n",
    "    \"\"\"Cleans header items found in some of the scraped datasets\"\"\"\n",
    "    return re.sub('([A-Z][^A-Z]+)', r'\\1 ', header).replace('- ', '-').strip()\n",
    "\n",
    "\n",
    "not_relevant_headers = ['description', 'introduction', 'summary', 'question', 'answer', 'conclusion']\n",
    "def prepend_heading_text(header: str) -> str:\n",
    "    \"\"\"Prepends the header if it contains useful information\"\"\"\n",
    "    header = clean_header(header)\n",
    "    lowered_header = header.lower()\n",
    "    for txt in not_relevant_headers:\n",
    "        if txt in lowered_header:\n",
    "            return ''\n",
    "    return f\"{header}\\n\"\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Takes in description and uses various regular expressions to clean it up somewhat.\"\"\"\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    text = re.sub('On [A-Z][a-z]*(?:| \\d*)\\, ([A-Z].+|\\d{4}.+)', '', text).strip() # Weird ask error\n",
    "    text = re.sub('\\-+(?:| )(?:Forwarded|Original).+', '', text).strip() \n",
    "    text = re.sub('\\. [A-Z][a-z]+$', '.', text)\n",
    "    text = re.sub(' From: [A-Z].+', '', text)\n",
    "    text = re.sub(' Sent from [A-Z].+', '', text)\n",
    "    text = text.replace('My 4-H ________ Project Record (000-00R)', '')\n",
    "    text = re.sub('((?:\\n|\\n | \\n)[^\\w]*)', r'\\n', text)\n",
    "    text = re.sub(' ([.,!?])', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "def chunk_data(txt: str) -> list:\n",
    "    \"\"\"Checks if text is over the maximum model length. If so, splits into chunks based on paragraphs\"\"\"\n",
    "    assert isinstance(txt, str)\n",
    "    token_length = get_token_length(txt)\n",
    "    if token_length >= MAX_LENGTH and '\\n' in txt:\n",
    "        txts = txt.split('\\n')\n",
    "        chunked = [chunk_data(t) for t in txts]\n",
    "        flattened = [t for chunk in chunked for t in chunk if t]\n",
    "        return flattened\n",
    "    elif token_length >= MAX_LENGTH:\n",
    "        return process_long_text(txt)\n",
    "    elif len(txt.split()) <= 12:\n",
    "        return []\n",
    "    else:\n",
    "        return [txt]\n",
    "\n",
    "def clean_dict_item(item: dict) -> str:\n",
    "    \"\"\"Assumes item has natural paragraph structure. \n",
    "        Breaks items into paragraphs, further splits into chunks if needed, and adds header if it's not generic\"\"\"\n",
    "    header = prepend_heading_text(item['header'])\n",
    "    texts = item['text'].split('\\n')\n",
    "    chunked_text = []\n",
    "    for text in texts:\n",
    "        text = clean_text(text)\n",
    "        chunked_text.extend(chunk_data(text))\n",
    "    if chunked_text:\n",
    "        chunked_text[0] = f\"{header}{chunked_text[0]}\"\n",
    "    return chunked_text \n",
    "\n",
    "def get_all_os_ticket_items(start_year: int = 2006, end_year: int = 2024):\n",
    "    \"\"\"Calls OS ticket API to get all ask extension data\"\"\"\n",
    "    for i in tqdm(range(start_year, end_year), desc='Calling OS Ticket API'):\n",
    "        start = str(i) \n",
    "        end = str(i+1)\n",
    "        url = f'https://qa.osticket.eduworks.com/api/knowledge/{start}-01-01/{end}-01-01'\n",
    "        try:\n",
    "            r = requests.get(url, timeout=40)\n",
    "            items = r.json()\n",
    "        except requests.exceptions.Timeout: \n",
    "            print(f\"{start}, {end}\")\n",
    "            continue\n",
    "\n",
    "        if items:\n",
    "            for item in items:\n",
    "                yield item    \n",
    "                \n",
    "def get_ask_extension_data() -> list:\n",
    "    \"\"\"Attempts to load from json. Though, will call os ticket API if not available\"\"\"    \n",
    "    try:\n",
    "        with open('raw_ask_extension_data.json', 'r', encoding='utf-8') as r:\n",
    "            return json.load(r)\n",
    "    except:\n",
    "        return list(get_all_os_ticket_items())       \n",
    "    \n",
    "    \n",
    "def get_ask_text(data: list) -> list:\n",
    "    unique_text = set()\n",
    "    for item in tqdm(data, desc=\"Adding Ask Extension Data\"):\n",
    "        url = get_link(item)\n",
    "        thumbnail = item['attachments'][0] if 'attachments' in item else ''\n",
    "        subhead = re.sub('\\#.+', '', item['title']).strip()\n",
    "        for k in item['answer']:\n",
    "            text = clean_text(item['answer'][k]['response'])\n",
    "            text = re.sub('([a-z,”:.])\\n([a-z“–])', r'\\1 \\2', text) # Weird line break in some answers\n",
    "            chunked_items = chunk_data(text)\n",
    "            for chunk in chunked_items:\n",
    "                chunk = re.sub('\\s+', ' ', chunk)\n",
    "                if chunk not in unique_text:\n",
    "                    unique_text.add(chunk)\n",
    "                    \n",
    "                    yield {'source': \"ask_extension_kb\", 'title': item['title'], 'url': url, 'text': chunk, 'thumbnail': thumbnail, \"subHead\": subhead}\n",
    "                     \n",
    "                \n",
    "def get_link(item: dict) -> str:\n",
    "    \"\"\"Creates ask url from faq-id\"\"\"\n",
    "    faq_id = item['faq-id']\n",
    "    return f\"https://ask2.extension.org/kb/faq.php?id={faq_id}\"  \n",
    "\n",
    "\n",
    "def load_json(path: str) -> list:\n",
    "    with open(path, 'r', encoding='utf-8') as r:\n",
    "        return json.load(r)\n",
    "    \n",
    "def is_qa_format(item: dict) -> bool:\n",
    "    \"\"\"Checks what type of format the dataset is in\"\"\"\n",
    "    if 'question' in item.keys() and 'answer' in item.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def get_source(url: str) -> str:\n",
    "    if 'clemson.edu' in url:\n",
    "        return 'clemson'\n",
    "    elif 'okstate.edu' in url:\n",
    "        return 'oklahoma_state'\n",
    "    elif 'oregonstate.edu' in url:\n",
    "        return 'oregon_state'\n",
    "    elif 'ipm.' in url or 'youtu' in url:\n",
    "        return 'uc_ipm'\n",
    "    else:\n",
    "        print(url)\n",
    "        raise Exception\n",
    "    \n",
    "def get_title(item: dict) -> str:\n",
    "    \"\"\"Finds title of item. If it doesn't exist, uses question\"\"\"\n",
    "    if 'title' in item:\n",
    "        return item['title']\n",
    "    elif 'question' in item:\n",
    "        return item['question']\n",
    "    else:\n",
    "        return '' \n",
    "        \n",
    "def get_thumbnail(item: dict) -> str:\n",
    "    if 'thumbnail' in item:\n",
    "        return item['thumbnail']\n",
    "    elif 'images' in item:\n",
    "        return item['images'][0]['src']\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def get_subheader(content_item):\n",
    "    if 'subHead' in content_item:\n",
    "        return content_item['subHead']\n",
    "    elif 'header' in content_item and (x:= prepend_heading_text(content_item['header'])):\n",
    "        return x\n",
    "    elif 'title' in content_item:\n",
    "        return content_item['title']\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "        \n",
    "def get_final_format(item: dict, chunk: str, content) -> dict:\n",
    "    url = item['url'] if 'url' in item else item['link']\n",
    "    source = get_source(url)\n",
    "    title = get_title(item)\n",
    "    thumbnail = item['thumbnail'] if 'thumbnail' in item else ''\n",
    "    subhead = get_subheader(item)\n",
    "    return {'source': source, 'title': title, 'url': url, 'text': chunk, 'thumbnail': thumbnail, \"subHead\": subhead}\n",
    "        \n",
    "def parse_qa_data(data: list) -> list:\n",
    "    if data:\n",
    "        relevant_text = [get_final_format(item, clean_text(v), item) for item in data for k,v in item.items() if k in ['question', 'answer']]\n",
    "        return  [get_final_format(item, chunk, item) for item in tqdm(relevant_text, desc='parsing qa data') for chunk in chunk_data(item['text']) if chunk]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def extract_qa_from_headers(data):\n",
    "    content, qa = [], []\n",
    "    for item in data:\n",
    "        if 'ask-expert' in item['link']:\n",
    "            qa.append(item)\n",
    "        else:\n",
    "            content.append(item)\n",
    "    return content, qa \n",
    "\n",
    "def extract_formatted_data(data: list):\n",
    "    if is_qa_format(data[0]):\n",
    "        return parse_qa_data(data)\n",
    "    else: \n",
    "        content_data, qa_data = extract_qa_from_headers(data)\n",
    "        qa_data = parse_qa_data(qa_data)\n",
    "        content_data = [get_final_format(item, chunk, content) for item in content_data for content in item['content'] for chunk in clean_dict_item(content) if chunk]\n",
    "        return qa_data + content_data\n",
    "    \n",
    "    \n",
    "def ingest_into_es(data: list, index: str):\n",
    "    \"\"\"Deleting any existing index and then ingesting the new data\"\"\"\n",
    "    def gen_data():\n",
    "        for item in tqdm(data, desc='Ingesting into Elasticsearch'):\n",
    "            yield {'_index': index, '_type': '_doc', **item}\n",
    "            \n",
    "    es_hosts = ['http://localhost:9200']\n",
    "    for es_host in es_hosts:\n",
    "        es = Elasticsearch([es_host], http_auth=('elastic', 'changeme'), timeout=140)\n",
    "        if es.indices.exists(index):\n",
    "            es.indices.delete(\n",
    "                index   = index, \n",
    "                ignore  = 404)\n",
    "            es.indices.refresh()\n",
    "        es.indices.create(index=index, mappings=MAPPINGS)\n",
    "        bulk(es, gen_data(), chunk_size=1000, request_timeout=120)\n",
    "    \n",
    "def save_data(path: str, all_data: list):\n",
    "    \"\"\"Saves as json and as a HuggingFace dataset for easy testing of the model\"\"\"\n",
    "    with open(f\"./{DATA_PATH}/{path}.json\", 'w', encoding = 'utf-8') as w:\n",
    "        json.dump(all_data, w, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    ds = Dataset.from_pandas(pd.DataFrame(all_data))\n",
    "    ds.save_to_disk(f'./{DATA_PATH}/{path}')\n",
    "    if 'test_' not in path:\n",
    "        all_data = get_vectors(all_data)\n",
    "        \n",
    "    ingest_into_es(all_data, path)\n",
    "    \n",
    "    print(f\"fully ingested {path} into elasticsearch\")\n",
    "    \n",
    "def parse_ask_extension_data():\n",
    "    ask_extension_data = get_ask_extension_data()\n",
    "    relevant_text = list(get_ask_text(ask_extension_data))\n",
    "    return relevant_text\n",
    "\n",
    "def get_vectors(all_data: list) -> list:\n",
    "    \"\"\"Vectorizing text in the dataset and then adding as a key in the list of dicts.\"\"\"\n",
    "    print(f\"\\nVectorizing {len(all_data)} items\\n\")\n",
    "    vectors = model.encode([item['text'] for item in all_data], batch_size=32, show_progress_bar=True).tolist()\n",
    "    return [{**item, \"vector\": vector} for item, vector in zip(all_data, vectors)]\n",
    "    \n",
    "def get_all_data():\n",
    "    paths = [f'./data/{f}'for f in os.listdir('./data')]\n",
    "    all_data = parse_ask_extension_data()\n",
    "    for path in paths:\n",
    "        if '.json' in path:\n",
    "            data = load_json(path)\n",
    "            formatted = extract_formatted_data(data)\n",
    "            all_data.extend(formatted)\n",
    "    save_data('chatbot_data', all_data)\n",
    "    return list(set([item['url'] for item in all_data]))\n",
    "    \n",
    "def parse_test_data(file: str, sheet_names: list, all_urls: list):\n",
    "    \"\"\"Retrieves questions and answer links from excel file. Stores in elastic search and saves to disk\"\"\"\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "        test_questions = []\n",
    "        for i, row in df.iterrows(): \n",
    "            \n",
    "            original_url = row['resource'] if 'resource' in df.columns else row['URL']\n",
    "            if isinstance(original_url, str):\n",
    "                url = f\"https://{original_url}\" if \"http\" not in original_url else original_url\n",
    "                question = row['question'] if 'question' in df.columns else row['Question']\n",
    "                if url and question and url in all_urls:\n",
    "                    test_questions.append({\"question\": question, \"url\": url, \"row\": i+2})\n",
    "        name = f'test_data_{sheet_name.lower()}'\n",
    "        save_data(path=name, all_data=test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_url = \"JeffEduworks/generalized_chatbot_model\"\n",
    "auth_token = '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'\n",
    "embed_cache_dir = '/var/tmp/models'\n",
    "\n",
    "embed = SentenceTransformer(\n",
    "    model_name_or_path  = embed_url         ,\n",
    "    use_auth_token      = auth_token        ,\n",
    "    cache_folder        = embed_cache_dir   ,\n",
    "    device              = 'cuda'             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f30bd5cd0147a89be6e85514f89f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.24987760e-02, -2.28405651e-02, -2.02608053e-02,\n",
       "         2.35038027e-02, -4.00520936e-02, -2.94942539e-02,\n",
       "         5.89871034e-02, -4.79837880e-02, -1.22409612e-02,\n",
       "         1.29854009e-02,  1.90039314e-02, -1.89917665e-02,\n",
       "         2.16116197e-03,  2.43839771e-02,  1.59765501e-02,\n",
       "         1.65427253e-02,  1.98328849e-02,  4.03242558e-02,\n",
       "        -4.50942218e-02, -2.94432268e-02,  3.00196987e-02,\n",
       "        -2.69945972e-02, -3.79857197e-02, -7.93182384e-03,\n",
       "         9.22650397e-02,  9.97528061e-03,  2.44988073e-02,\n",
       "         2.57510059e-02, -1.02928672e-02, -5.47002256e-02,\n",
       "         4.16536070e-02, -3.89104616e-03, -2.63434704e-02,\n",
       "         8.11946020e-02, -2.57553836e-08, -1.56465061e-02,\n",
       "         4.50725742e-02,  3.70585755e-03,  1.78355556e-02,\n",
       "         3.97871956e-02,  1.89350992e-02,  2.89250985e-02,\n",
       "        -1.23737929e-02,  1.26444036e-02,  2.34889835e-02,\n",
       "        -2.52409130e-02,  1.08108460e-03, -4.56883721e-02,\n",
       "         2.25954372e-02, -2.88477838e-02, -6.26340136e-03,\n",
       "        -6.75254017e-02, -1.09430104e-02, -2.04777792e-02,\n",
       "         4.75628637e-02,  5.49458265e-02,  2.28730328e-02,\n",
       "        -2.33834386e-02,  6.57967851e-02, -4.13547009e-02,\n",
       "         3.21648479e-03, -2.96770670e-02,  4.69809677e-03,\n",
       "        -1.63739398e-02,  7.34446496e-02,  2.88834181e-02,\n",
       "         6.18584454e-02, -1.80368256e-02,  3.65307070e-02,\n",
       "         8.27954859e-02,  1.52829178e-02,  3.69383022e-02,\n",
       "        -2.72030290e-02,  4.41952161e-02, -3.67647856e-02,\n",
       "        -4.12651745e-04, -3.07926536e-03, -9.68499482e-02,\n",
       "         2.81016920e-02,  1.27346138e-04,  3.32473852e-02,\n",
       "         4.95533012e-02, -9.90996021e-04,  4.71176393e-02,\n",
       "        -2.09604073e-02,  6.99773757e-03,  4.15612059e-03,\n",
       "         1.05883274e-03,  2.10480001e-02, -1.67552866e-02,\n",
       "        -2.81784055e-03,  8.29497259e-03, -1.48482095e-05,\n",
       "        -2.37651225e-02, -6.03756644e-02, -2.47003008e-02,\n",
       "         5.61440326e-02, -6.23556301e-02,  4.91559766e-02,\n",
       "        -2.00719517e-02,  5.47083281e-02,  3.90849188e-02,\n",
       "        -3.90530303e-02, -7.02474732e-03, -8.99432302e-02,\n",
       "         1.11181447e-02,  4.86549735e-02, -5.05038202e-02,\n",
       "         2.57971939e-02,  4.97553013e-02,  9.88890696e-03,\n",
       "         4.23516743e-02,  3.93236950e-02,  1.54425791e-02,\n",
       "         5.98369958e-03, -3.99701335e-02, -6.92222491e-02,\n",
       "         3.37569229e-03, -4.84815650e-02,  2.89249960e-02,\n",
       "         6.17534965e-02,  1.05195381e-02,  1.47407660e-02,\n",
       "         5.17088249e-02, -1.62368435e-02,  5.52707911e-02,\n",
       "        -4.97499369e-02,  4.99511324e-02,  3.03319898e-02,\n",
       "        -3.36365635e-03, -3.88179384e-02,  3.12327668e-02,\n",
       "         8.54816288e-03, -7.15706963e-03, -2.44713742e-02,\n",
       "         6.10912256e-02,  7.77656503e-04,  8.83801840e-03,\n",
       "         2.57835314e-02,  5.94732687e-02,  1.33657875e-02,\n",
       "        -2.80345175e-02, -1.79399010e-02, -6.38177544e-02,\n",
       "        -2.80932672e-02, -2.73227450e-02, -3.80828381e-02,\n",
       "        -8.04656278e-03,  4.51486837e-03, -2.19816193e-02,\n",
       "         7.93265030e-02, -2.07095463e-02, -5.11544617e-03,\n",
       "         1.94980334e-02,  4.16511074e-02, -1.88983195e-02,\n",
       "        -3.96220349e-02, -3.82055342e-02, -1.45059926e-02,\n",
       "         6.50183931e-02,  2.55389623e-02,  2.96345111e-02,\n",
       "        -2.38312129e-02, -1.82261262e-02,  4.35884297e-03,\n",
       "        -2.68443953e-02, -1.90113876e-02,  2.11259369e-02,\n",
       "        -1.71295647e-02,  4.35529500e-02, -1.60719026e-02,\n",
       "         5.34399878e-03, -2.99414676e-02, -2.57048588e-02,\n",
       "         6.92106485e-02, -4.12203111e-02,  6.37124479e-02,\n",
       "        -8.96922424e-02, -1.55843049e-02, -6.20926917e-03,\n",
       "         4.46947031e-02,  2.22501773e-02,  3.67039554e-02,\n",
       "        -3.75288315e-02,  3.37116644e-02,  3.18339989e-02,\n",
       "         2.29557641e-02,  2.06922367e-03,  9.20517650e-03,\n",
       "         1.46969948e-02,  4.20943499e-02, -1.45000033e-02,\n",
       "         1.84706803e-02,  2.51592174e-02,  2.05388274e-02,\n",
       "         1.31701538e-02,  2.94583011e-03, -8.53327215e-02,\n",
       "         1.61545370e-02,  5.17904721e-02, -8.73405486e-02,\n",
       "         3.23821977e-02,  2.18523871e-02, -1.55259864e-02,\n",
       "        -4.62648198e-02, -3.77886780e-02, -5.32993153e-02,\n",
       "        -6.64371764e-03,  1.50890788e-02, -1.13077844e-02,\n",
       "        -5.27573330e-03,  2.70760134e-02,  8.62376764e-02,\n",
       "        -6.90620244e-02,  1.54468017e-02, -4.02628258e-02,\n",
       "         2.06357744e-02,  3.36811170e-02, -2.75205472e-03,\n",
       "         7.35974163e-02, -3.78257735e-03,  5.14875501e-02,\n",
       "        -4.01285961e-02,  3.96327935e-02, -1.02176601e-02,\n",
       "         2.07210705e-02,  5.99838942e-02, -2.90562641e-02,\n",
       "        -1.77641623e-02,  2.46931799e-02,  1.40740856e-04,\n",
       "        -1.22925155e-02,  2.72402610e-03, -2.11491194e-02,\n",
       "         3.81008200e-02, -4.86307554e-02, -8.29824153e-03,\n",
       "        -4.82369401e-02,  1.16347976e-03, -3.27463225e-02,\n",
       "        -1.26353493e-02, -1.59771531e-03,  4.32386715e-03,\n",
       "        -4.25814241e-02,  1.58049446e-02,  1.31355962e-04,\n",
       "         2.08713040e-02,  3.10221687e-02, -4.22017686e-02,\n",
       "        -2.38692784e-03,  3.10514811e-02, -3.29276989e-03,\n",
       "         2.24897042e-02, -1.95537470e-02,  2.01219134e-02,\n",
       "         3.03242152e-04, -1.32259913e-02, -6.74829185e-02,\n",
       "         2.38140877e-02,  1.94093920e-02, -9.85927694e-03,\n",
       "         2.18771808e-02,  9.68619715e-03, -3.91705111e-02,\n",
       "         3.59540284e-02,  4.30254638e-02, -1.12091927e-02,\n",
       "         7.05983490e-02,  1.86044350e-02, -2.10518744e-02,\n",
       "        -2.54886365e-03, -3.36244889e-02,  6.02771752e-02,\n",
       "         3.35334912e-02,  3.04262433e-02, -9.80262831e-02,\n",
       "         3.63436388e-03,  4.09882031e-02, -9.04690996e-02,\n",
       "         4.04090099e-02,  5.66798486e-02, -2.29784995e-02,\n",
       "        -2.81201880e-02, -1.30223401e-03,  6.72927946e-02,\n",
       "         1.09027186e-02, -5.70767820e-02, -4.45804186e-02,\n",
       "         5.27827814e-02, -7.94130750e-03, -1.89601872e-02,\n",
       "        -2.49487963e-02, -1.15249502e-02, -8.76631681e-03,\n",
       "        -2.60196757e-02, -5.18115098e-03, -5.31054400e-02,\n",
       "        -2.94890106e-02, -2.55833846e-02, -7.97107518e-02,\n",
       "        -4.42646071e-02,  1.28818247e-02, -5.69329821e-02,\n",
       "        -4.09390666e-02,  1.38360390e-03,  1.32821465e-03,\n",
       "         4.18791324e-02, -7.91754574e-03, -1.37000363e-02,\n",
       "        -1.67164095e-02, -2.06056889e-02, -9.15471837e-03,\n",
       "         4.11949418e-02, -3.01227104e-02,  4.79393266e-02,\n",
       "         3.13517898e-02,  6.74273074e-02, -2.26279302e-03,\n",
       "         4.24828641e-02, -1.35448948e-02, -1.47731798e-02,\n",
       "         1.47934910e-02,  3.86015251e-02, -2.17011608e-02,\n",
       "        -4.02801111e-02,  1.60000566e-02, -6.11552410e-02,\n",
       "        -3.16473320e-02, -8.22915286e-02,  6.65465090e-03,\n",
       "        -4.29846067e-03, -7.35551342e-02,  1.10537419e-02,\n",
       "        -4.92169075e-02, -3.91237903e-03,  7.39900395e-02,\n",
       "        -7.56726647e-03,  4.70831059e-02,  2.92072389e-02,\n",
       "         1.09260678e-02, -1.87371280e-02, -5.73220849e-02,\n",
       "        -1.43183442e-02,  1.19327903e-01, -3.58155966e-02,\n",
       "        -3.29920314e-02, -1.82223208e-02,  1.90386884e-02,\n",
       "        -3.01655810e-02, -9.39544570e-03, -5.52486219e-02,\n",
       "         1.17630111e-02,  2.03866325e-03, -1.09522715e-02,\n",
       "         1.10822722e-04,  6.46252837e-03, -4.17111665e-02,\n",
       "        -2.77616875e-03,  6.22851364e-02, -1.04375910e-02,\n",
       "         6.94830716e-02,  3.69086377e-02, -2.56190822e-02,\n",
       "        -5.75065874e-02, -3.52190621e-02,  1.49054397e-02,\n",
       "         2.53435336e-02, -3.94656993e-02, -2.32374426e-02,\n",
       "        -3.30800600e-02, -3.97654697e-02, -2.10504048e-03,\n",
       "         5.88000044e-02, -1.19958892e-02, -8.40195734e-03,\n",
       "        -1.50383366e-02, -3.49086686e-03,  1.57841239e-02,\n",
       "         3.80786397e-02, -2.99222395e-03, -1.37738055e-02,\n",
       "        -6.67941868e-02, -4.24075574e-02, -6.60211826e-03,\n",
       "         2.64472254e-02,  4.54885028e-02, -1.98436715e-02,\n",
       "        -2.48750821e-02,  3.83597389e-02, -2.08433438e-02,\n",
       "         3.76084470e-03, -1.93312149e-02, -6.72690978e-04,\n",
       "         1.40964534e-04,  9.11251921e-03, -2.25742869e-02,\n",
       "        -4.63876547e-03, -4.94820112e-03, -2.71016313e-03,\n",
       "         1.31458603e-02, -5.72433090e-03,  6.25279769e-02,\n",
       "        -2.18835641e-02,  1.93349104e-02, -1.65462345e-02,\n",
       "         2.58403830e-02,  8.70883539e-02,  2.55203936e-02,\n",
       "         2.38047615e-02, -7.25758597e-02,  3.73824053e-02,\n",
       "        -8.48965533e-03,  1.43637892e-03,  8.63293465e-03,\n",
       "        -6.36879075e-03, -4.73608598e-02,  3.83842215e-02,\n",
       "        -1.17585352e-02,  1.19012035e-02, -4.00243402e-02,\n",
       "        -2.11527273e-02,  1.54995322e-02, -7.02550784e-02,\n",
       "         1.42579479e-02,  1.97942574e-02, -3.86122689e-02,\n",
       "         4.35243659e-02, -2.57672817e-02, -1.75091475e-02,\n",
       "         3.88636403e-02,  4.97455671e-02, -4.68580239e-02,\n",
       "        -8.55082460e-03,  2.69757099e-02,  1.74812339e-02,\n",
       "         1.27338135e-04, -1.74080916e-02,  2.15267465e-02,\n",
       "        -2.39499919e-02, -3.74357738e-02, -2.96735242e-02,\n",
       "        -2.47172988e-03,  2.55758725e-02, -2.31071562e-02,\n",
       "        -3.16612795e-03,  3.76339094e-03,  2.87633669e-02,\n",
       "         4.16780449e-02, -2.40375996e-02,  6.28778040e-02,\n",
       "         2.02315692e-02, -3.16291936e-02, -4.94599044e-02,\n",
       "         5.01131676e-02,  2.62524635e-02, -1.28131043e-02,\n",
       "         3.43880765e-02,  1.46205071e-02, -8.51453748e-03,\n",
       "         6.54601306e-03, -6.69126445e-03,  4.32480462e-02,\n",
       "        -6.96306229e-02,  1.01151951e-02,  3.58855613e-02,\n",
       "        -4.96136546e-02,  1.99289024e-02, -3.24366055e-02,\n",
       "        -5.11249229e-02,  2.09031980e-02, -8.06731358e-02,\n",
       "        -2.35428587e-02, -4.35123499e-03, -1.08884051e-02,\n",
       "         3.83839011e-02, -1.54019324e-02, -2.19226927e-02,\n",
       "         2.46280488e-02, -6.84628088e-04, -2.83262338e-02,\n",
       "        -3.81371565e-02,  2.21161637e-02, -3.09615508e-02,\n",
       "         2.23813560e-02, -3.94085720e-02,  9.06185340e-03,\n",
       "         1.69290751e-02,  2.38544010e-02, -2.89006904e-02,\n",
       "         2.38020048e-02,  2.41267961e-03,  4.07871641e-02,\n",
       "        -1.50138140e-02, -6.44644797e-02,  6.45027980e-02,\n",
       "        -4.99957092e-02, -4.22944240e-02, -7.85391554e-02,\n",
       "         2.23181508e-02,  2.22288612e-02,  1.38927689e-02,\n",
       "         2.95736007e-02, -3.53500694e-02, -1.36248944e-02,\n",
       "         3.26497927e-02,  8.28726590e-03, -7.24650994e-02,\n",
       "         1.44769978e-02,  3.73344459e-02,  1.81807447e-02,\n",
       "         2.35053152e-02, -7.03503517e-03, -3.66037488e-02,\n",
       "        -3.22120227e-02, -1.49981733e-02,  4.83905245e-03,\n",
       "         8.24164599e-02, -4.82336944e-03, -8.67048930e-03,\n",
       "         2.51514968e-02,  2.41268985e-02, -7.23413005e-03,\n",
       "         2.85604279e-02,  3.97029854e-02, -2.70403903e-02,\n",
       "        -9.44676325e-02,  2.91337334e-02, -5.92888519e-02,\n",
       "         1.82494968e-02,  5.93782105e-02, -6.63539171e-02,\n",
       "         1.49295880e-02, -3.62692848e-02, -8.13437160e-03,\n",
       "        -6.11012615e-02,  1.24672065e-02, -1.84281431e-02,\n",
       "         5.35517894e-02, -3.64248566e-02, -6.23982809e-02,\n",
       "        -5.90280630e-02, -1.81934368e-02, -3.02378256e-02,\n",
       "         1.91888574e-03,  3.14293592e-03,  2.32144762e-02,\n",
       "        -1.08594149e-02, -4.28080522e-02,  5.51761687e-02,\n",
       "         5.76678477e-02,  4.42380682e-02,  2.27810815e-02,\n",
       "        -6.30269945e-02, -4.41905297e-02, -1.29716061e-02,\n",
       "        -1.21116447e-15, -3.29582160e-03,  3.54930982e-02,\n",
       "        -5.21285385e-02, -2.77574025e-02,  1.32117532e-02,\n",
       "         1.15820090e-03, -4.39587459e-02,  2.13430859e-02,\n",
       "        -1.21206678e-02,  1.56531855e-02,  8.15687887e-03,\n",
       "        -5.65581024e-04,  3.02584711e-02,  4.17526513e-02,\n",
       "        -3.72496545e-02, -2.51722056e-02,  2.71132439e-02,\n",
       "         1.78621821e-02,  5.87443542e-03,  2.99946237e-02,\n",
       "        -8.80445316e-02,  2.50132177e-02, -1.17668211e-01,\n",
       "         6.69172034e-02,  4.14811075e-02, -3.86944599e-02,\n",
       "         3.07533368e-02, -5.61368391e-02, -4.14019749e-02,\n",
       "        -2.62952759e-04,  1.28785614e-03,  9.16302577e-03,\n",
       "        -3.03810462e-02,  9.62414816e-02, -5.10223061e-02,\n",
       "        -4.99403961e-02, -1.02003124e-02,  1.10287191e-02,\n",
       "        -5.99343702e-02,  6.96171401e-03, -3.04346196e-02,\n",
       "         9.05031688e-04,  1.85259096e-02, -2.03616992e-02,\n",
       "        -7.91021157e-03,  8.27427059e-02,  2.50737034e-02,\n",
       "        -1.08538307e-02, -1.54563328e-02, -5.93856275e-02,\n",
       "        -1.57648437e-02,  2.05277596e-02, -6.09401567e-03,\n",
       "        -2.13278737e-02, -4.56615817e-03,  7.66873136e-02,\n",
       "         3.97414006e-02, -2.85966769e-02, -6.79046139e-02,\n",
       "         3.03641800e-02, -3.11177280e-02, -4.53557968e-02,\n",
       "        -9.90114175e-03, -8.60346388e-03,  1.19224959e-03,\n",
       "         8.54981318e-03,  1.32830873e-01, -3.42200361e-02,\n",
       "         8.23509097e-02,  2.03203168e-02, -1.51310768e-02,\n",
       "         3.53577994e-02,  4.91891615e-02, -3.04850601e-02,\n",
       "        -3.65936756e-02, -9.35529396e-02, -1.84262227e-02,\n",
       "        -5.01597160e-03,  1.75803639e-02, -4.85434616e-03,\n",
       "        -3.52175459e-02,  2.96544097e-02,  1.82272512e-02,\n",
       "         1.26184039e-02,  2.01132447e-02,  6.62492588e-02,\n",
       "         7.17186253e-04,  2.07584817e-02, -2.02790238e-02,\n",
       "         3.78404297e-02, -4.91009420e-03,  1.65220965e-02,\n",
       "         2.58477312e-03, -2.48822346e-02,  6.24407455e-02,\n",
       "        -4.16190326e-02, -5.87129481e-02,  1.40513051e-02,\n",
       "        -1.91595759e-02, -2.61433199e-02,  5.40585164e-03,\n",
       "         4.08371575e-02,  7.10550975e-03,  2.12112237e-02,\n",
       "         3.40457610e-03, -7.44873483e-04, -1.20320460e-02,\n",
       "        -3.20997015e-02, -2.75741350e-02,  4.03200649e-02,\n",
       "        -4.06352356e-02,  4.21020687e-02,  1.22031206e-02,\n",
       "        -3.67338434e-02, -1.78591739e-02, -2.35430840e-02,\n",
       "         2.50765253e-02,  2.68544592e-02, -8.89417436e-03,\n",
       "        -1.15004415e-02, -7.18763610e-03,  3.63931544e-02,\n",
       "         6.55398741e-02,  2.17499919e-02, -8.06615800e-02,\n",
       "        -6.16321748e-04,  3.53585705e-02,  2.17291582e-02,\n",
       "        -3.49141844e-02,  1.85710322e-02, -4.89441305e-03,\n",
       "        -2.67534945e-02,  3.59663346e-07, -8.46110098e-03,\n",
       "         3.25144008e-02,  2.29784008e-02, -6.02974044e-03,\n",
       "         1.28336041e-03,  1.15410695e-02, -1.99638470e-03,\n",
       "        -2.82558780e-02, -2.63842400e-02,  2.74499115e-02,\n",
       "         1.49566196e-02, -3.98514830e-02,  3.35669182e-02,\n",
       "         5.61980195e-02,  4.69634309e-02, -4.29872721e-02,\n",
       "         1.40377963e-02,  1.49698015e-02,  4.02880460e-03,\n",
       "        -5.36794029e-03, -4.82755676e-02,  4.48608026e-02,\n",
       "        -1.74631644e-02,  2.09148116e-02, -2.73417658e-03,\n",
       "        -1.87957920e-02, -3.32606025e-02,  2.84868386e-03,\n",
       "         6.35728836e-02,  8.03940115e-04,  3.67513560e-02,\n",
       "         2.82802843e-02, -4.21768948e-02, -5.17254770e-02,\n",
       "         1.19720520e-02, -1.85384192e-02,  2.34954059e-02,\n",
       "        -7.60515314e-03, -9.59859975e-03, -2.56558717e-03,\n",
       "        -1.55935697e-02, -1.86215229e-02,  1.16101205e-02,\n",
       "        -4.58243154e-02, -2.70083826e-02,  3.93597335e-02,\n",
       "        -5.15487976e-02, -1.96364280e-02, -2.79595014e-02,\n",
       "        -2.43292339e-02,  9.08338130e-02,  2.43351441e-02,\n",
       "        -1.90548552e-03,  3.56709547e-02,  1.33671882e-02,\n",
       "        -3.02296448e-02, -5.29850600e-04, -1.92595143e-02,\n",
       "        -8.84562638e-03, -1.82142407e-02, -2.20257752e-02,\n",
       "        -7.76135735e-03,  1.65508199e-03,  9.11650285e-02,\n",
       "         3.74974385e-02, -5.19731129e-03,  4.65218490e-03,\n",
       "        -1.18034707e-35, -2.70633977e-02, -4.58729872e-03,\n",
       "        -6.39543589e-03,  3.11311875e-02, -2.06084084e-02,\n",
       "         1.19990320e-03,  5.04423678e-02,  6.11296156e-03,\n",
       "         1.40209477e-02,  2.88352221e-02, -2.73676366e-02]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.encode(['Dauren is the best'], show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('es-data-ingestion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "607e550c5f7577ecefb8f11c45030a36424a53b9c08a45019262888187990ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
